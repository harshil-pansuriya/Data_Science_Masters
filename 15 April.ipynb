{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b065eaaf-22e3-40a4-a853-30e2f973688c",
   "metadata": {},
   "source": [
    "# 1.\n",
    "## You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "### -> Design a pipeline that includes the following steps:\n",
    "#### Use an automated feature selection method to identify the important features in the dataset.\n",
    "### -> Create a numerical pipeline that includes the following steps:\n",
    "#### Impute the missing values in the numerical columns using the mean of the column values.\n",
    "#### Scale the numerical columns using standardisation.\n",
    "### -> Create a categorical pipeline that includes the following steps:\n",
    "#### Impute the missing values in the categorical columns using the most frequent value of the columns\n",
    "#### One-hot encode the categorical columns.\n",
    "#### Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "#### Use a Random Forest Classifier to build the final model.\n",
    "#### Evaluate the accuracy of the model on the test dataset.\n",
    "#### Note! Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6959bbf-4085-47d4-b8af-5828faa6442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "    # Assuming X_train and y_train are your training data and labels\n",
    "    # Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "# Fit the Random Forest Classifier on the data\n",
    "X_test,X_train,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "# Use feature_importances_ attribute to get feature importance scores\n",
    "feature_imp = clf.feature_importances_\n",
    "# Use SelectFromModel to select important features\n",
    "sfm = SelectFromModel(rf_clf, threshold=0.5)\n",
    "X_train_selected = sfm.fit_transform(X_train, y_train)\n",
    "\n",
    "# Numerical pipeline that imputes the missing values and scales the columns.\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "# Impute the missing values in the numerical columns.\n",
    "numerical_pipeline.fit(df[imp_features].drop('target', axis=1))\n",
    "df[imp_features] = numerical_pipeline.transform(df[imp_features].drop('target', axis=1))\n",
    "\n",
    "# Categorical Pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
    "('encoder', OneHotEncoder())  ]) # One-hot encode categorical features \n",
    "    \n",
    "# Create ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "('num', numerical_pipeline, numerical_features),\n",
    "('cat', categorical_pipeline, categorical_features) ])\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "('feature_selection', SelectFromModel(RandomForestClassifier(), threshold=threshold)),\n",
    "('preprocessing', preprocessor),\n",
    "('classifier', RandomForestClassifier()) ])\n",
    "\n",
    "\n",
    "# Assuming X_test and y_test are your test data and labels\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2851f69-0a82-4fac-8b55-6622081bf913",
   "metadata": {},
   "source": [
    "# 2.\n",
    "## Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a57820-1c28-4f6f-9dee-60e44c8b4c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "# Create individual classifiers\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create the Voting Classifier with 'hard' voting (simple majority voting)\n",
    "clf3 = VotingClassifier(\n",
    "    estimators=[('rf', clf1), ('lr', clf2)],\n",
    "    voting='hard' )\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('voting', clf3)\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e526de3-7634-419a-94e4-15c5d222387c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
